{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe448d5",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Neural Networks\n",
    "\n",
    "Using Krohn (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d280a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import nltk.stem as stemmer\n",
    "\n",
    "import string\n",
    "\n",
    "import gensim\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pandas as pd\n",
    "from bokeh.io import output_notebook, output_file\n",
    "from bokeh.plotting import show, figure\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c53fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca58eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the corpus into a list of sentences\n",
    "gberg_sent_tokens = sent_tokenize(gutenberg.raw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize further into sentences as list of lists\n",
    "gberg_sents = gutenberg.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900ecee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all to lowercase\n",
    "[w.lower() for w in gberg_sents[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words and punctuation\n",
    "stpwrds = stopwords.words('english') + list(string.punctuation)\n",
    "[w.lower() for w in gberg_sents[4] if w.lower() not in stpwrds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb8112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming words using the Porter algorithm built in to NLTK\n",
    "[stemmer.stem(w.lower()) for w in gberg_sents[4]\n",
    "if w.lower() not in stpwrds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ba446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling n-grams so that something like New York is counted as one word and not two \n",
    "phrases = Phrases(gberg_sents)\n",
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8681c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing a sentence by using split method\n",
    "tokenized_sentence = 'John lives in New York City'.split()\n",
    "print(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b1e189",
   "metadata": {},
   "source": [
    "Now that we've gone through some basic preprocessing requests, we can easily preprocess the entire corpus in one step rather than so many tedious steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8a1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_sents = []\n",
    "for s in gberg_sents:\n",
    "    lower_sents.append([w.lower() for w in s if w.lower() \n",
    "                       not in list(string.punctuation)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# too low of a threshold in the traditional way of scoring bigrams, so we need to cap what is considered a bigram\n",
    "lower_bigram = Phraser(Phrases(lower_sents, min_count=32, threshold = 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477541b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create a clean corpus that includes bigrams \n",
    "clean_sents = []\n",
    "for s in lower_sents:\n",
    "    clean_sents.append(lower_bigram[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0587c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2224e69",
   "metadata": {},
   "source": [
    "Now that we have a clean corpus of data, we can embed words from the corpus into the word-vector space. word2vec uses predictive models, GloVe uses count models and is good across multiple NLP applications, fastText is good for subword level, so good for rare words and out of vocabulary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243dfdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use word2vec here\n",
    "# sentences is a list of lists as a corpus\n",
    "# size is the number of dimensions that the word vector space will result\n",
    "# sg set to 1 to choose the skip-gram architecture or leave at 0 for CBOW (this is a small corpus, so using SG)\n",
    "# window is good to be 10 for sg and 5 for CBOW, means the context words considered\n",
    "# iter by default is 5, multiple iters is like multiple epochs\n",
    "# min_count is the number of times a word must occur in order to fit into the word vector space\n",
    "# workers is the number of processing cores committed to this task\n",
    "model = Word2Vec(sentences=clean_sents,\n",
    "                sg=1, window=10,\n",
    "                min_count=10, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f110993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('clean_gutenberg_model.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f7094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can load up prebuilt vectors instead too\n",
    "model = gensim.models.Word2Vec.load('clean_gutenberg_model.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fcd3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most similar method checks to make sure the word vectors are quality\n",
    "model.wv.most_similar('father', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a2112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which word does not belong\n",
    "model.wv.doesnt_match(\"mother father sister brother dog\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d4a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check familiarity score\n",
    "model.wv.similarity('father', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute vfather - vman + vwoman to test the word vector analogies\n",
    "model.wv.most_similar(positive=['father', 'woman'], negative =['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ebcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['husband', 'woman'], negative =['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca09a90",
   "metadata": {},
   "source": [
    "t-distributed stochastic neighbor embedding (t-SNE) means we can compress vectors to two or three dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6dd506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_components is the number of dimensions that should be returned\n",
    "# n_iter is the number of iterations over the input data, analogous to epochs associated with training neural network\n",
    "\n",
    "tsne = TSNE(n_components=2, n_iter=1000)\n",
    "X_2d = tsne.fit_transform(model.wv[model.wv.vocab])\n",
    "coords_df = pd.DataFrame(X_2d, columns=['x','y'])\n",
    "coords_df['token']=model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470dd314",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_df = pd.read_csv('clean_gutenberg_tsne.csv')\n",
    "coords_df.head()\n",
    "_ = coords_df.plot.scatter('x','y', figsize=(12,12), marker='.', s=10, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also have interactive bokeh plot\n",
    "output_notebook()\n",
    "subset_df=coords_df.sample(n=5000)\n",
    "p=figure(plot_width=800, plot_height=800)\n",
    "_=p.text(x=subset_df.x, y=subset_df.y, text=subset_df.token)\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
